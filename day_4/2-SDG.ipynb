{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCk2Rx4cjlYF"
   },
   "source": [
    "# Synthetic Data Generation Using RAGAS - RAG Evaluation with LangSmith\n",
    "\n",
    "In the following notebook we'll explore a use-case for RAGAS' synthetic testset generation workflow!\n",
    "\n",
    "\n",
    "  1. Use RAGAS to Generate Synthetic Data\n",
    "  2. Load them into a LangSmith Dataset\n",
    "  3. Evaluate our RAG chain against the synthetic test data\n",
    "  4. Make changes to our pipeline\n",
    "  5. Evaluate the modified pipeline\n",
    "\n",
    "SDG is a critical piece of the puzzle, especially for early iteration! Without it, it would not be nearly as easy to get high quality early signal for our application's performance.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VUI7vF_kbv9"
   },
   "source": [
    "## Task 1: Dependencies and API Keys\n",
    "\n",
    "We'll need to install a number of API keys and dependencies, since we'll be leveraging a number of great technologies for this pipeline!\n",
    "\n",
    "1. OpenAI's endpoints to handle the Synthetic Data Generation\n",
    "2. OpenAI's Endpoints for our RAG pipeline and LangSmith evaluation\n",
    "3. QDrant as our vectorstore\n",
    "4. LangSmith for our evaluation coordinator!\n",
    "\n",
    "Let's install and provide all the required information below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and API Keys:\n",
    "\n",
    "> NOTE: DO NOT RUN THESE CELLS IF YOU ARE RUNNING THIS NOTEBOOK LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU ragas==0.2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU langchain-community==0.3.14 langchain-openai==0.2.14 unstructured==0.16.12 langgraph==0.2.61 langchain-qdrant==0.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Import\n",
    "\n",
    "To prevent errors that may occur based on OS - we'll import NLTK and download the needed packages to ensure correct handling of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMINN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ADMINN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LangChain API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also want to set a project name to make things easier for ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"PSI - SDG - {uuid4().hex[0:8]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI's API Key!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Test Data\n",
    "\n",
    "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
    "\n",
    "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "We'll prepare our data - which should hopefull be familiar at this point since it's our Loan Data use-case!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "\n",
    "path = \"bills/\"\n",
    "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph Based Synthetic Generation\n",
    "\n",
    "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
    "\n",
    "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrolled SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to instantiate our Knowledge Graph.\n",
    "\n",
    "This graph will contain N number of nodes that have M number of relationships. These nodes and relationships (AKA \"edges\") will define our knowledge graph and be used later to construct relevant questions and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 0, relationships: 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step we're going to take is to simply insert each of our full documents into the graph. This will provide a base that we can apply transformations to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 20, relationships: 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "### NOTICE: We're using a subset of the data for this example - this is to keep costs/time down.\n",
    "for doc in docs[:20]:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll apply the *default* transformations to our knowledge graph. This will take the nodes currently on the graph and transform them based on a set of [default transformations](https://docs.ragas.io/en/latest/references/transforms/#ragas.testset.transforms.default_transforms).\n",
    "\n",
    "These default transformations are dependent on the corpus length, in our case:\n",
    "\n",
    "- Producing Summaries -> produces summaries of the documents\n",
    "- Extracting Headlines -> finding the overall headline for the document\n",
    "- Theme Extractor -> extracts broad themes about the documents\n",
    "\n",
    "It then uses cosine-similarity and heuristics between the embeddings of the above transformations to construct relationships between the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312148373a204bedbc666bc87ec3c1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e688c8188e4c6ebbcc0effdf628b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Node 58038132-80b2-472b-b0bc-0b29337d72d5 does not have a summary. Skipping filtering.\n",
      "Node 083f6085-a681-4aaf-98d9-7f2e91002272 does not have a summary. Skipping filtering.\n",
      "Node ae2945a2-1dcd-4535-8f13-5ddcb1bcff38 does not have a summary. Skipping filtering.\n",
      "Node 50934c92-9cd8-4516-b2e0-d764e08196a9 does not have a summary. Skipping filtering.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb8ba738ab44c9f8bebd8c90fe1e88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766bc2ac05bb4993a0d157c323b7703b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 20, relationships: 136)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "transformer_llm = generator_llm\n",
    "embedding_model = generator_embeddings\n",
    "\n",
    "default_transforms = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n",
    "apply_transforms(kg, default_transforms)\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save and load our knowledge graphs as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 20, relationships: 136)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.save(\"bills/ai_law.json\")\n",
    "bills_data_kg = KnowledgeGraph.load(\"bills/ai_law.json\")\n",
    "bills_data_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our knowledge graph, we can construct a \"test set generator\" - which will allow us to create queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=bills_data_kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we'd like to be able to define the kinds of queries we're generating - which is made simple by Ragas having pre-created a number of different \"QuerySynthesizer\"s.\n",
    "\n",
    "Each of these Synthetsizers is going to tackle a separate kind of query which will be generated from a scenario and a persona.\n",
    "\n",
    "In essence, Ragas will use an LLM to generate a persona of someone who would interact with the data - and then use a scenario to construct a question from that data and persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
    "\n",
    "query_distribution = [\n",
    "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "#### ❓ Question #1:\n",
    "\n",
    "What are the three types of query synthesizers doing? Describe each one in simple terms.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "### Answer :\n",
    "\n",
    "* The three types of query synthesizers generate different kinds of questions for evaluating retrieval-augmented generation systems: the SingleHopSpecificQuerySynthesizer creates simple, direct questions answerable with a single fact; the MultiHopAbstractQuerySynthesizer generates more complex, conceptual questions that require connecting multiple pieces of information; and the MultiHopSpecificQuerySynthesizer produces detailed, focused questions that also require combining several facts, but in a concrete and specific way.\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use our `TestSetGenerator` to generate our testset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d44dd4c7154c4db2b0a67438c1e36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3209394fde14958a000c3569b9e03a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c309930e1af4c69b5376f36c924ea89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What role does the European Union play in AI r...</td>\n",
       "      <td>[TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...</td>\n",
       "      <td>The European Union's landmark AI Act of 2024 h...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What Georgetown University do about AI risks?</td>\n",
       "      <td>[AI presents enormous opportunities for the Ph...</td>\n",
       "      <td>The context does not specify actions taken by ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you explain what AIRA stands for and its s...</td>\n",
       "      <td>[TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...</td>\n",
       "      <td>AIRA refers to the Artificial Intelligence Reg...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How AI is promote innovation and responsible u...</td>\n",
       "      <td>[1 \\na) Promote innovation, technological adva...</td>\n",
       "      <td>The context states that AI should promote inno...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does AGI mean in AI and why is it importa...</td>\n",
       "      <td>[1\\n2\\n3\\n4\\n5\\n6\\n7\\n8 \\n9\\n10\\n11\\n12\\n13\\n1...</td>\n",
       "      <td>Artificial General Intelligence (AGI) refers t...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does the review process of AI risks, inclu...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\na) Promote innovation, technol...</td>\n",
       "      <td>The review process of AI risks involves the AI...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does the naic promote AI in sectors like a...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nSec. 8. NAICSecretariat. - The...</td>\n",
       "      <td>The NAIC promotes AI in sectors such as agricu...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H0w do penalties for AI-related crimminal acti...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\ndevelopment priorities. These ...</td>\n",
       "      <td>The context indicates that penalties for AI-re...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>how ASI surpass humans and AI risks like hallu...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8 \\n9\\n10\\n11...</td>\n",
       "      <td>the context explains that Artificial Superinte...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does the DICT's role in AI regulation rela...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nSec. 6. Jurisdiction of the NA...</td>\n",
       "      <td>The DICT is part of the NAIC, which has jurisd...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>how Sec 11 and Sec 16 relate to AI risk classi...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nSec. 8. NAICSecretariat. - The...</td>\n",
       "      <td>Sec 11 of the act mandates the maintenance of ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   What role does the European Union play in AI r...   \n",
       "1       What Georgetown University do about AI risks?   \n",
       "2   Can you explain what AIRA stands for and its s...   \n",
       "3   How AI is promote innovation and responsible u...   \n",
       "4   What does AGI mean in AI and why is it importa...   \n",
       "5   How does the review process of AI risks, inclu...   \n",
       "6   How does the naic promote AI in sectors like a...   \n",
       "7   H0w do penalties for AI-related crimminal acti...   \n",
       "8   how ASI surpass humans and AI risks like hallu...   \n",
       "9   How does the DICT's role in AI regulation rela...   \n",
       "10  how Sec 11 and Sec 16 relate to AI risk classi...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...   \n",
       "1   [AI presents enormous opportunities for the Ph...   \n",
       "2   [TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...   \n",
       "3   [1 \\na) Promote innovation, technological adva...   \n",
       "4   [1\\n2\\n3\\n4\\n5\\n6\\n7\\n8 \\n9\\n10\\n11\\n12\\n13\\n1...   \n",
       "5   [<1-hop>\\n\\n1 \\na) Promote innovation, technol...   \n",
       "6   [<1-hop>\\n\\n1 \\nSec. 8. NAICSecretariat. - The...   \n",
       "7   [<1-hop>\\n\\n1 \\ndevelopment priorities. These ...   \n",
       "8   [<1-hop>\\n\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8 \\n9\\n10\\n11...   \n",
       "9   [<1-hop>\\n\\n1 \\nSec. 6. Jurisdiction of the NA...   \n",
       "10  [<1-hop>\\n\\n1 \\nSec. 8. NAICSecretariat. - The...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The European Union's landmark AI Act of 2024 h...   \n",
       "1   The context does not specify actions taken by ...   \n",
       "2   AIRA refers to the Artificial Intelligence Reg...   \n",
       "3   The context states that AI should promote inno...   \n",
       "4   Artificial General Intelligence (AGI) refers t...   \n",
       "5   The review process of AI risks involves the AI...   \n",
       "6   The NAIC promotes AI in sectors such as agricu...   \n",
       "7   The context indicates that penalties for AI-re...   \n",
       "8   the context explains that Artificial Superinte...   \n",
       "9   The DICT is part of the NAIC, which has jurisd...   \n",
       "10  Sec 11 of the act mandates the maintenance of ...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstracted SDG\n",
    "\n",
    "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
    "\n",
    "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefd767143bf4bc9b6a17e13314e3b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26171a8e6cc493a8b908decc20cfeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Node eff3d17f-91d5-42a9-afc9-072104dd2935 does not have a summary. Skipping filtering.\n",
      "Node 7192e678-e847-4cc1-bf66-b02ec953b514 does not have a summary. Skipping filtering.\n",
      "Node f3b73e2b-ccfb-411e-b001-3a78ac8463e8 does not have a summary. Skipping filtering.\n",
      "Node f4d48441-df79-4be1-9f9f-969d78e64e44 does not have a summary. Skipping filtering.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e2ddd4385546e19f210dce13b21b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2821af9cde04ed48eebaae8cbe0f809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fa640c9d2a4c8e970ee277507320a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38f806f482d4a6b954df669fc1c2f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc7449985e94dddb442b29cb60e60eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs[:20], testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the role of CD0 Magazine in discussing...</td>\n",
       "      <td>[TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...</td>\n",
       "      <td>According to the provided context, CD0 Magazin...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the potential risks associated with t...</td>\n",
       "      <td>[AI presents enormous opportunities for the Ph...</td>\n",
       "      <td>The context indicates that Artificial Superint...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Article XIV?</td>\n",
       "      <td>[TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...</td>\n",
       "      <td>Article XIV is a section of the Philippine Con...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of ASI in the context...</td>\n",
       "      <td>[1 \\na) Promote innovation, technological adva...</td>\n",
       "      <td>The context states that the Act shall regulate...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do intrinsic hallucination and extrinsic h...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nground its responses in verifi...</td>\n",
       "      <td>Intrinsic hallucination occurs when the AI mod...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does AI regulation address worker displace...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nd) Take full responsibility fo...</td>\n",
       "      <td>The AI regulation framework requires employers...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>support for tech vocational education and disc...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\niii) \\nProof of employer engag...</td>\n",
       "      <td>The context shows that there is support for te...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what are the responsibilities of AI developers...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nSec. 15. AI Ethics Review Boar...</td>\n",
       "      <td>The responsibilities of AI developers, deploye...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does TESDA contribute to AI regulation and...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nd) Take full responsibility fo...</td>\n",
       "      <td>TESDA is involved in AI regulation and workfor...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does the NAIC's regulation of AI in employ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nd) Take full responsibility fo...</td>\n",
       "      <td>The NAIC's regulation of AI in employment and ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does the DOST contribute to the developmen...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\niii) \\nProof of employer engag...</td>\n",
       "      <td>The DOST contributes to AI-related employment ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How do the penalties imposed by the DOST for A...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nendorsements, voice recordings...</td>\n",
       "      <td>The penalties imposed by the DOST for AI-relat...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   What is the role of CD0 Magazine in discussing...   \n",
       "1   What are the potential risks associated with t...   \n",
       "2                                What is Article XIV?   \n",
       "3   What is the significance of ASI in the context...   \n",
       "4   How do intrinsic hallucination and extrinsic h...   \n",
       "5   How does AI regulation address worker displace...   \n",
       "6   support for tech vocational education and disc...   \n",
       "7   what are the responsibilities of AI developers...   \n",
       "8   How does TESDA contribute to AI regulation and...   \n",
       "9   How does the NAIC's regulation of AI in employ...   \n",
       "10  How does the DOST contribute to the developmen...   \n",
       "11  How do the penalties imposed by the DOST for A...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...   \n",
       "1   [AI presents enormous opportunities for the Ph...   \n",
       "2   [TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...   \n",
       "3   [1 \\na) Promote innovation, technological adva...   \n",
       "4   [<1-hop>\\n\\n1 \\nground its responses in verifi...   \n",
       "5   [<1-hop>\\n\\n1 \\nd) Take full responsibility fo...   \n",
       "6   [<1-hop>\\n\\n1 \\niii) \\nProof of employer engag...   \n",
       "7   [<1-hop>\\n\\n1 \\nSec. 15. AI Ethics Review Boar...   \n",
       "8   [<1-hop>\\n\\n1 \\nd) Take full responsibility fo...   \n",
       "9   [<1-hop>\\n\\n1 \\nd) Take full responsibility fo...   \n",
       "10  [<1-hop>\\n\\n1 \\niii) \\nProof of employer engag...   \n",
       "11  [<1-hop>\\n\\n1 \\nendorsements, voice recordings...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   According to the provided context, CD0 Magazin...   \n",
       "1   The context indicates that Artificial Superint...   \n",
       "2   Article XIV is a section of the Philippine Con...   \n",
       "3   The context states that the Act shall regulate...   \n",
       "4   Intrinsic hallucination occurs when the AI mod...   \n",
       "5   The AI regulation framework requires employers...   \n",
       "6   The context shows that there is support for te...   \n",
       "7   The responsibilities of AI developers, deploye...   \n",
       "8   TESDA is involved in AI regulation and workfor...   \n",
       "9   The NAIC's regulation of AI in employment and ...   \n",
       "10  The DOST contributes to AI-related employment ...   \n",
       "11  The penalties imposed by the DOST for AI-relat...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vSRr2MXk0P_"
   },
   "source": [
    "We'll need to provide our LangSmith API key, and set tracing to \"true\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SLtk1GtnyoY"
   },
   "source": [
    "## Task 4: LangSmith Dataset\n",
    "\n",
    "Now we can move on to creating a dataset for LangSmith!\n",
    "\n",
    "First, we'll need to create a dataset on LangSmith using the `Client`!\n",
    "\n",
    "We'll name our Dataset to make it easy to work with later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing dataset: Philippines AI Bills\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"Philippines AI Bills\"\n",
    "\n",
    "try:\n",
    "    # Try to get the existing dataset\n",
    "    langsmith_dataset = client.read_dataset(dataset_name=dataset_name)\n",
    "    print(f\"Using existing dataset: {dataset_name}\")\n",
    "except Exception:\n",
    "    # If it doesn't exist, create it\n",
    "    langsmith_dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=\"Philippines AI Bills\"\n",
    "    )\n",
    "    print(f\"Created new dataset: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64SmXMBnzXWm"
   },
   "source": [
    "We'll iterate through the RAGAS created dataframe - and add each example to our created dataset!\n",
    "\n",
    "> NOTE: We need to conform the outputs to the expected format - which in this case is: `question` and `answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8nFQ6di_XnY7"
   },
   "outputs": [],
   "source": [
    "for data_row in dataset.to_pandas().iterrows():\n",
    "  client.create_example(\n",
    "      inputs={\n",
    "          \"question\": data_row[1][\"user_input\"]\n",
    "      },\n",
    "      outputs={\n",
    "          \"answer\": data_row[1][\"reference\"]\n",
    "      },\n",
    "      metadata={\n",
    "          \"context\": data_row[1][\"reference_contexts\"]\n",
    "      },\n",
    "      dataset_id=langsmith_dataset.id\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6EbQVyZq-2j"
   },
   "source": [
    "## Basic RAG Chain\n",
    "\n",
    "Time for some RAG!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4njbUAIsaYjB"
   },
   "outputs": [],
   "source": [
    "rag_documents = docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQorBy8H1AZR"
   },
   "source": [
    "To keep things simple, we'll just use LangChain's recursive character text splitter!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "qWo3Ajaragv1"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kghuTb9R01oO"
   },
   "source": [
    "We'll create our vectorstore using OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UwfJCzP3aqKI"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpCLS-a01Ft2"
   },
   "source": [
    "As usual, we will power our RAG application with Qdrant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "58Ypj_NgbEsi"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"AI Bills RAG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "SbKSjfSkbTYo"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxUOMaQX1K2N"
   },
   "source": [
    "To get the \"A\" in RAG, we'll provide a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1sLeY1oWbVqO"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZnHDh4e1Ou5"
   },
   "source": [
    "For our LLM, we will be using TogetherAI's endpoints as well!\n",
    "\n",
    "We're going to be using Meta Llama 3.1 70B Instruct Turbo - a powerful model which should get us powerful results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "6nx-ue1XbciV"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmTL6-pc1ZGz"
   },
   "source": [
    "Finally, we can set-up our RAG LCEL chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "TjWj0OLIbbFc"
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WQ7bEweo4IIb",
    "outputId": "d161b269-f799-4920-d6ce-c202f6e783aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The penalty for using AI to create or disseminate disinformation is:\\n\\n- A fine of One Million Pesos (Php 1,000,000) to Five Million Pesos (Php 5,000,000),  \\n- or imprisonment of three (3) years to ten (10) years,  \\n- or both, at the discretion of the court.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\" : \"How much is the penalty for spreading disinformation?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9hBh5YPrdGJ"
   },
   "source": [
    "## LangSmith Evaluation Set-up\n",
    "\n",
    "We'll use OpenAI's GPT-4.1 as our evaluation LLM for our base Evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "gfwPYdIkcvpF"
   },
   "outputs": [],
   "source": [
    "eval_llm = ChatOpenAI(model=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b8pToKH2K28"
   },
   "source": [
    "We'll be using a number of evaluators - from LangSmith provided evaluators, to a few custom evaluators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "PXSG-_ajckp6"
   },
   "outputs": [],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
    "\n",
    "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : eval_llm})\n",
    "\n",
    "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"helpfulness\": (\n",
    "                \"Is this submission helpful to the user,\"\n",
    "                \" taking into account the correct reference answer?\"\n",
    "            )\n",
    "        },\n",
    "        \"llm\" : eval_llm\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"output\"],\n",
    "        \"reference\": example.outputs[\"answer\"],\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "empathy_evaluator = LangChainStringEvaluator(\n",
    "    \"criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"empathy\": \"Is this response empathetic? Does it make the user feel like they are being heard?\",\n",
    "        },\n",
    "        \"llm\" : eval_llm\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0SQP_FoCetP"
   },
   "source": [
    "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "#### 🏗️ Question #2:\n",
    "\n",
    "Highlight what each evaluator is evaluating.\n",
    "\n",
    "- `qa_evaluator`:\n",
    "- `labeled_helpfulness_evaluator`:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "### Answer:\n",
    "\n",
    "* qa_evaluator: This evaluator checks if the model’s answer is correct and relevant to the question, using an LLM to compare the generated answer with the reference answer.\n",
    "\n",
    "* labeled_helpfulness_evaluator: This evaluator measures how helpful the model’s answer is to the user, specifically considering if the answer would assist the user when compared to the correct reference answer. It uses an LLM and a custom “helpfulness” criterion.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R35sQMHVrnpl"
   },
   "source": [
    "## LangSmith Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "122b1bd1f0e9417a8dcb57d4eebe4d2e",
      "e0c233ad01604540a6c873f4a731982d",
      "e9a01115c75b499884f7e0ef32e9e599",
      "5faba4ad609448b2b49024add4ad3b8e",
      "ef25efa751304e4699910f1fbc14345f",
      "0b44cb0f8e34446c8dde668a75d3d8ad",
      "edaac6587b2d4bd5be52b89bb097f99f",
      "7cb241365f604419af454c1c28de197a",
      "9cf586576ff44dba86ba2eb389593c61",
      "849b5c95008541d49f1ceedf0a59ac60",
      "f3665a86662746c4ac7cb0796604781d"
     ]
    },
    "id": "t7t_Uz0tdumL",
    "outputId": "d684e218-294e-4dc3-c8de-a01d397f021c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'mealy-shape-82' at:\n",
      "https://smith.langchain.com/o/7fc042b4-97e0-5f3f-b110-30a87bc46433/datasets/2e682626-7edb-4606-ad73-4627a7519185/compare?selectedSessions=35f267b3-9e14-4f42-a0f3-425327fe27b0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a931382ddd42a4ad5f61cfceccea78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.empathy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do the penalties imposed by the DOST for A...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>The penalties imposed by the DOST for AI-relat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.108801</td>\n",
       "      <td>9dce146f-36f2-463f-b8b9-badab90cee69</td>\n",
       "      <td>b0fe8095-82b7-4c10-9245-384acfff2f47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the DOST contribute to the developmen...</td>\n",
       "      <td>Based on the provided context, the Department ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The DOST contributes to AI-related employment ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.096888</td>\n",
       "      <td>bf43c5bd-6c53-4285-b11c-e47e5a88f21f</td>\n",
       "      <td>4c866ff5-d2d3-488e-87fc-63145b7cce08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the NAIC's regulation of AI in employ...</td>\n",
       "      <td>Based on the provided context, the NAIC is res...</td>\n",
       "      <td>None</td>\n",
       "      <td>The NAIC's regulation of AI in employment and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.471050</td>\n",
       "      <td>570050a8-5f4d-4cbd-b8c1-c8e5521bb151</td>\n",
       "      <td>26cdaf5d-e519-431d-a729-ca8ae7b31459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does TESDA contribute to AI regulation and...</td>\n",
       "      <td>According to the context, TESDA contributes to...</td>\n",
       "      <td>None</td>\n",
       "      <td>TESDA is involved in AI regulation and workfor...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.202665</td>\n",
       "      <td>f62dffa5-225f-4663-bd7f-8aa3c52784c3</td>\n",
       "      <td>75e20600-3f61-4b9d-b05c-2d64d6622c8f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are the responsibilities of AI developers...</td>\n",
       "      <td>Based on the provided context, AI developers, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The responsibilities of AI developers, deploye...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.341976</td>\n",
       "      <td>2adb0549-7c0b-4d29-bc70-0a569e96ec66</td>\n",
       "      <td>cec7c75e-d1f8-467c-9b81-afce3c113f9f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>support for tech vocational education and disc...</td>\n",
       "      <td>Based on the provided context, the Act promote...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context shows that there is support for te...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.491835</td>\n",
       "      <td>c8370608-4d85-4e65-a43e-3c3ce8a55a68</td>\n",
       "      <td>fd57ffd0-3bfc-4406-9715-88fe0fc6ed8e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does AI regulation address worker displace...</td>\n",
       "      <td>AI regulation addresses worker displacement an...</td>\n",
       "      <td>None</td>\n",
       "      <td>The AI regulation framework requires employers...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.487035</td>\n",
       "      <td>f273ef67-9a8f-4ad9-9b9e-4bd652854ff8</td>\n",
       "      <td>c15a4f1d-299a-46bf-9d31-cb21cb044b2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do intrinsic hallucination and extrinsic h...</td>\n",
       "      <td>Intrinsic hallucination occurs when an AI mode...</td>\n",
       "      <td>None</td>\n",
       "      <td>Intrinsic hallucination occurs when the AI mod...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.298744</td>\n",
       "      <td>d40085c2-0202-4e88-892c-a6c40bc697f6</td>\n",
       "      <td>af88a69b-0832-4e18-a061-a36b0bc182aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the significance of ASI in the context...</td>\n",
       "      <td>The significance of Artificial Superintelligen...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context states that the Act shall regulate...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.475439</td>\n",
       "      <td>0bc32b5f-db58-4757-9f90-9b9314daf362</td>\n",
       "      <td>6c8de114-9ab4-46e8-9171-8539cf5ed241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is Article XIV?</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>Article XIV is a section of the Philippine Con...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.011127</td>\n",
       "      <td>7286e944-6353-464d-a512-07460b952588</td>\n",
       "      <td>f4a344f3-6691-4b54-a5f9-b52d02a027d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What are the potential risks associated with t...</td>\n",
       "      <td>The potential risks associated with the rise o...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that Artificial Superint...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.189895</td>\n",
       "      <td>605e60a1-07fc-4ba7-9943-255e3e524ccf</td>\n",
       "      <td>913221f4-8661-4305-ad0f-5111d08ecda9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is the role of CD0 Magazine in discussing...</td>\n",
       "      <td>Based on the provided context, CD0 Magazine is...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to the provided context, CD0 Magazin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.711101</td>\n",
       "      <td>d7fa72f1-8b83-4db2-9b1a-1d3210f084fd</td>\n",
       "      <td>87e40fb8-1017-40e2-a951-ca1588d6b858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How does the AI registration process ensure co...</td>\n",
       "      <td>The AI registration process ensures compliance...</td>\n",
       "      <td>None</td>\n",
       "      <td>The AI registration process, as outlined in th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.429667</td>\n",
       "      <td>8a60db1e-52a7-4dbe-a0d1-4ad4021b4b3d</td>\n",
       "      <td>c2a48251-70ae-4570-b783-adc37e32b90c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How do the AI policies ensure ethical standard...</td>\n",
       "      <td>The AI policies ensure ethical standards and r...</td>\n",
       "      <td>None</td>\n",
       "      <td>The AI policies establish an AI Ethics Review ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.038945</td>\n",
       "      <td>01fea1e0-8654-41e6-bbcf-877f5789ff7d</td>\n",
       "      <td>b3915bb9-2a8d-484a-bd2d-2a7b91bd1d43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>how dictt and dictt r related in ai polcy?</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context shows that the DICT (Department of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.180136</td>\n",
       "      <td>ef57f6db-625c-4191-81a8-5953c8b09eb8</td>\n",
       "      <td>49ac1d2f-9012-4063-9091-956e7098dcd3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How do Sec. 11 and Sec. 16 relate to AI risk c...</td>\n",
       "      <td>Based on the provided context:\\n\\n- Section 11...</td>\n",
       "      <td>None</td>\n",
       "      <td>Sec. 16 outlines the classification of AI syst...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.548805</td>\n",
       "      <td>39f5df27-1cfc-4ade-8518-dc02dcbd99a5</td>\n",
       "      <td>0d45b10f-c52a-40e2-9253-2970443efcf3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How do the penalties for manipulatn and prohib...</td>\n",
       "      <td>The penalties for manipulation and prohibited ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context shows that penalties for manipulat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.944908</td>\n",
       "      <td>b76c9779-ce7e-493b-b25f-97ce53cd2199</td>\n",
       "      <td>240e7601-6735-404e-8c99-57dab8b89fc8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How do the AI registration requirements outlin...</td>\n",
       "      <td>Based on the provided context, the AI registra...</td>\n",
       "      <td>None</td>\n",
       "      <td>The requirements in Sec. 12 mandate that each ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.931298</td>\n",
       "      <td>de81a08c-8c8a-474b-a1b3-875683b7a9e2</td>\n",
       "      <td>15381e31-aceb-4011-a17a-ceb48562b7e8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>how do big language models and the rules about...</td>\n",
       "      <td>Based on the provided context, the AI Regulati...</td>\n",
       "      <td>None</td>\n",
       "      <td>big language models (LLMs) are a type of gener...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.375575</td>\n",
       "      <td>5c1a08cd-a740-4add-920c-4f4fcbb178e2</td>\n",
       "      <td>215e5d1e-06a9-4ed6-a4ff-9e46c11bb5c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How do the ai registration requirments and pen...</td>\n",
       "      <td>Based on the provided context, AI registration...</td>\n",
       "      <td>None</td>\n",
       "      <td>The ai registration and registry requirements ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.287796</td>\n",
       "      <td>4d5e512d-2ab4-46e9-9410-2ebb5cf8ba95</td>\n",
       "      <td>650370b4-f318-4118-9af3-ad5c49de1d6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>How does the policy aim to protect Filipinos i...</td>\n",
       "      <td>The policy aims to protect Filipinos in the co...</td>\n",
       "      <td>None</td>\n",
       "      <td>The policy aims to promote the responsible and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.261878</td>\n",
       "      <td>89cca42e-bb2a-4170-be8c-e35b89feb354</td>\n",
       "      <td>0e32a3aa-ba07-44cc-88d4-210ffe5f94e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What was the significance of the TWENTIETH CON...</td>\n",
       "      <td>The significance of the TWENTIETH CONGRESS in ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The TWENTIETH CONGRESS of the Republic of the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.122948</td>\n",
       "      <td>ea05552d-c4c3-4ad0-a260-a471b42e5bb0</td>\n",
       "      <td>25c1787f-033e-40a2-a78b-ed17d1f25805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ASI dangerous?</td>\n",
       "      <td>Based on the context, Artificial Superintellig...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context mentions that the rise of Artifici...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.454126</td>\n",
       "      <td>beb210ca-9360-4424-bff8-c80a8afe80ad</td>\n",
       "      <td>88b93c43-b619-49b1-b395-66f9bcf94ee1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What does the TWENTIETH CONGRESS do about AI p...</td>\n",
       "      <td>The TWENTIETH CONGRESS OF THE REPUBLIC OF THE ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The TWENTIETH CONGRESS OF THE REPUBLIC OF THE ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.154939</td>\n",
       "      <td>16137a07-e531-41d1-9ccc-5fa09ad9ec5f</td>\n",
       "      <td>c4126f3a-f39a-4413-b361-20deac4fb561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults mealy-shape-82>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    rag_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"default_chain_init\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nq7fCVinrpI4"
   },
   "source": [
    "## Dope-ifying Our Application\n",
    "\n",
    "We'll be making a few changes to our RAG chain to increase its performance on our SDG evaluation test dataset!\n",
    "\n",
    "- Include a \"dope\" prompt augmentation\n",
    "- Use larger chunks\n",
    "- Improve the retriever model to: `text-embedding-3-large`\n",
    "\n",
    "Let's see how this changes our evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "z56pXwyUgFUt"
   },
   "outputs": [],
   "source": [
    "EMPATHY_RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "You must answer the question using empathy and kindness, and make sure the user feels heard.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "empathy_rag_prompt = ChatPromptTemplate.from_template(EMPATHY_RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "rZLcTstJgfv5"
   },
   "outputs": [],
   "source": [
    "rag_documents = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-LYsyirngj6n"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spldiPuTCzDO"
   },
   "source": [
    "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "### ❓Question #2:\n",
    "\n",
    "Why would modifying our chunk size modify the performance of our application?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "### Answer: \n",
    "\n",
    "Modifying the chunk size changes how much text is grouped together and retrieved at once from the documents. If the chunks are too small, important context might be split up and missed by the model, leading to incomplete or less accurate answers. If the chunks are too large, irrelevant information may be included, making it harder for the model to find the most relevant details. Therefore, finding the right chunk size helps balance context and relevance, directly impacting the quality and performance of the application's responses.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "b9MI2Bm2go1r"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBbjG6cKC8BQ"
   },
   "source": [
    "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "#### ❓Question #3:\n",
    "\n",
    "Why would modifying our embedding model modify the performance of our application?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "### Answer :\n",
    "\n",
    "Modifying the embedding model changes how the application represents and understands the meaning of text. Different embedding models vary in their ability to capture semantic relationships, context, and nuances in language. A more advanced or better-suited embedding model can improve how well the system matches questions to relevant information, leading to more accurate and helpful responses. While a less capable model might miss important connections, reducing performance. So, the choice of embedding model directly affects the quality of retrieval and, ultimately, the application's effectiveness.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "hVUY25FKgxXx"
   },
   "outputs": [],
   "source": [
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"AI Bills RAG 2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Q4TOZNYIg2v1"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqYGFrnKDB91"
   },
   "source": [
    "Setting up our new and improved DOPE RAG CHAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "HqnTqeXMhAdx"
   },
   "outputs": [],
   "source": [
    "empathy_rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | empathy_rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21pTxoqJDI1Y"
   },
   "source": [
    "Let's test it on the same output that we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "OfZZ3MoN3fKv",
    "outputId": "d65722dd-92c2-4e4e-9cca-c42ee6f3f208"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you for your thoughtful question. Based on the context provided, the Philippines AI Bill is important because it aims to carefully balance the encouragement of technological innovation with ensuring that AI systems remain safe, ethical, transparent, and under meaningful human oversight. It recognizes that AI is still in its early stages and provides a general framework to promote responsible and lawful AI development.\\n\\nMoreover, the bill envisions a future where AI supports Filipino ingenuity, tackles national development challenges, and protects the rights and welfare of every citizen. It also underscores the State’s responsibility to prevent AI from being used to commit crimes, violate rights, or cause harm, whether deliberately or accidentally, all while fostering technological progress.\\n\\nI appreciate your interest in understanding this significant legislation that seeks to guide AI innovation thoughtfully and responsibly in the Philippines. If you have more questions or need further clarification, feel free to ask!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empathy_rag_chain.invoke({\"question\" : \"Why is the Philippines AI Bill important?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpj7v1inDLnQ"
   },
   "source": [
    "Finally, we can evaluate the new chain on the same test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "bf8dcc0895054529af356da401c513f6",
      "7dce19ac55264f2b88a0e4730e55867b",
      "2a0755d4476543feb4a64538e3e37213",
      "158212a630f04cbd884c937f2f60f5c8",
      "11c7f66acc1d45be9517d0addf49331e",
      "ddffd834e09940a4bd3874c3f39b4e21",
      "ef63c3b2d51e452da03cdae5d9b034be",
      "c20b539cd70b4ba99601ad1d69fd9cec",
      "a6d681eeafa44d18b933a4c5dec88382",
      "d1d54ccd56494c4d831f71b416a1f880",
      "530f696feefe499da08c6312047379b2"
     ]
    },
    "id": "Dx11S2b-hIM8",
    "outputId": "d3a3ea78-aa32-4bd2-8c2a-d0d0303695c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'artistic-acknowledgment-32' at:\n",
      "https://smith.langchain.com/o/7fc042b4-97e0-5f3f-b110-30a87bc46433/datasets/2e682626-7edb-4606-ad73-4627a7519185/compare?selectedSessions=b0594322-bfb8-49c0-acee-1a8c260627ee\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48a5395db694680b53c421fd7df0fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.empathy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do the penalties imposed by the DOST for A...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The penalties imposed by the DOST for AI-relat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.133611</td>\n",
       "      <td>9dce146f-36f2-463f-b8b9-badab90cee69</td>\n",
       "      <td>1cf2a76d-997c-4ae6-abbc-5855413f3c89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the DOST contribute to the developmen...</td>\n",
       "      <td>Thank you for asking such a thoughtful questio...</td>\n",
       "      <td>None</td>\n",
       "      <td>The DOST contributes to AI-related employment ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.068426</td>\n",
       "      <td>bf43c5bd-6c53-4285-b11c-e47e5a88f21f</td>\n",
       "      <td>ad0f5828-f766-42f3-a27d-fffb4fbb196b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the NAIC's regulation of AI in employ...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The NAIC's regulation of AI in employment and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.375062</td>\n",
       "      <td>570050a8-5f4d-4cbd-b8c1-c8e5521bb151</td>\n",
       "      <td>f1db498e-4cc3-4763-a9c3-ca61ee5f2ce6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does TESDA contribute to AI regulation and...</td>\n",
       "      <td>Thank you for your thoughtful question. It’s c...</td>\n",
       "      <td>None</td>\n",
       "      <td>TESDA is involved in AI regulation and workfor...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.420858</td>\n",
       "      <td>f62dffa5-225f-4663-bd7f-8aa3c52784c3</td>\n",
       "      <td>5a2f7502-48ca-4224-89f5-09559bee64dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are the responsibilities of AI developers...</td>\n",
       "      <td>Thank you for your thoughtful question about t...</td>\n",
       "      <td>None</td>\n",
       "      <td>The responsibilities of AI developers, deploye...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.644590</td>\n",
       "      <td>2adb0549-7c0b-4d29-bc70-0a569e96ec66</td>\n",
       "      <td>40132d8d-2fd3-4e87-ab3a-960be9fa1c17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>support for tech vocational education and disc...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context shows that there is support for te...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.952384</td>\n",
       "      <td>c8370608-4d85-4e65-a43e-3c3ce8a55a68</td>\n",
       "      <td>998d06c3-6a73-42bd-89e9-0b86ca4b957e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does AI regulation address worker displace...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The AI regulation framework requires employers...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.256042</td>\n",
       "      <td>f273ef67-9a8f-4ad9-9b9e-4bd652854ff8</td>\n",
       "      <td>39092809-2caa-453a-b7dc-b0d7176ab356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do intrinsic hallucination and extrinsic h...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Intrinsic hallucination occurs when the AI mod...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.389153</td>\n",
       "      <td>d40085c2-0202-4e88-892c-a6c40bc697f6</td>\n",
       "      <td>d59233b9-1dd6-4487-a9af-f5a9d05212b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the significance of ASI in the context...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context states that the Act shall regulate...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.493394</td>\n",
       "      <td>0bc32b5f-db58-4757-9f90-9b9314daf362</td>\n",
       "      <td>752e637a-28c2-42fd-babd-81cd91137dcd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is Article XIV?</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Article XIV is a section of the Philippine Con...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.315485</td>\n",
       "      <td>7286e944-6353-464d-a512-07460b952588</td>\n",
       "      <td>4226e2e8-2193-48cf-b47b-3c435a916268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What are the potential risks associated with t...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context indicates that Artificial Superint...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.835753</td>\n",
       "      <td>605e60a1-07fc-4ba7-9943-255e3e524ccf</td>\n",
       "      <td>130ccbdf-e8f7-42d5-ae4f-b9d6af1f020b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is the role of CD0 Magazine in discussing...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to the provided context, CD0 Magazin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.559351</td>\n",
       "      <td>d7fa72f1-8b83-4db2-9b1a-1d3210f084fd</td>\n",
       "      <td>918f53f9-4653-4808-9586-7835be3bf20b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How does the AI registration process ensure co...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The AI registration process, as outlined in th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.702943</td>\n",
       "      <td>8a60db1e-52a7-4dbe-a0d1-4ad4021b4b3d</td>\n",
       "      <td>e0775fdc-fd01-490d-a004-e1aa8c3fb869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How do the AI policies ensure ethical standard...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The AI policies establish an AI Ethics Review ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.069522</td>\n",
       "      <td>01fea1e0-8654-41e6-bbcf-877f5789ff7d</td>\n",
       "      <td>e07e1339-8865-41d8-b213-40eba7764457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>how dictt and dictt r related in ai polcy?</td>\n",
       "      <td>Thank you for your question. I want to make su...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context shows that the DICT (Department of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.598794</td>\n",
       "      <td>ef57f6db-625c-4191-81a8-5953c8b09eb8</td>\n",
       "      <td>4a3f5dd8-1a55-4589-aedf-4f64779f3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How do Sec. 11 and Sec. 16 relate to AI risk c...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Sec. 16 outlines the classification of AI syst...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.736265</td>\n",
       "      <td>39f5df27-1cfc-4ade-8518-dc02dcbd99a5</td>\n",
       "      <td>1e10a45d-0a01-4d5e-83aa-25f14b3f4ca0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How do the penalties for manipulatn and prohib...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context shows that penalties for manipulat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.434339</td>\n",
       "      <td>b76c9779-ce7e-493b-b25f-97ce53cd2199</td>\n",
       "      <td>c4d8c3a4-d75e-40dc-8e0e-4482c7cdff34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How do the AI registration requirements outlin...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The requirements in Sec. 12 mandate that each ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.542941</td>\n",
       "      <td>de81a08c-8c8a-474b-a1b3-875683b7a9e2</td>\n",
       "      <td>9b7dd7b4-775e-492e-a962-9adf73e506ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>how do big language models and the rules about...</td>\n",
       "      <td>Thank you for your thoughtful question—it's cl...</td>\n",
       "      <td>None</td>\n",
       "      <td>big language models (LLMs) are a type of gener...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.546481</td>\n",
       "      <td>5c1a08cd-a740-4add-920c-4f4fcbb178e2</td>\n",
       "      <td>7e4bf781-3987-40c3-af49-447140e46c4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How do the ai registration requirments and pen...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The ai registration and registry requirements ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.050846</td>\n",
       "      <td>4d5e512d-2ab4-46e9-9410-2ebb5cf8ba95</td>\n",
       "      <td>b75affdc-0c8a-4c09-8b1f-d9258643797d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>How does the policy aim to protect Filipinos i...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The policy aims to promote the responsible and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.901607</td>\n",
       "      <td>89cca42e-bb2a-4170-be8c-e35b89feb354</td>\n",
       "      <td>320aa697-849b-4d6d-a1ca-875a1ae95095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What was the significance of the TWENTIETH CON...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The TWENTIETH CONGRESS of the Republic of the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.886938</td>\n",
       "      <td>ea05552d-c4c3-4ad0-a260-a471b42e5bb0</td>\n",
       "      <td>eca1400d-b5c3-42ff-93ee-1bf243586b17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ASI dangerous?</td>\n",
       "      <td>Thank you for your thoughtful question about A...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context mentions that the rise of Artifici...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.670252</td>\n",
       "      <td>beb210ca-9360-4424-bff8-c80a8afe80ad</td>\n",
       "      <td>dbe703fc-53d7-407d-9799-37a8a06488a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What does the TWENTIETH CONGRESS do about AI p...</td>\n",
       "      <td>Thank you for your question. Based on the cont...</td>\n",
       "      <td>None</td>\n",
       "      <td>The TWENTIETH CONGRESS OF THE REPUBLIC OF THE ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.367029</td>\n",
       "      <td>16137a07-e531-41d1-9ccc-5fa09ad9ec5f</td>\n",
       "      <td>8eb6b64c-b458-4322-a7b6-ffeb8a29e7f0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults artistic-acknowledgment-32>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    empathy_rag_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"empathy_rag_chain\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C7migvlDPZT"
   },
   "source": [
    "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "#### 🏗️ Question #4:\n",
    "\n",
    "Explain why you believe certain metrics changed in certain ways, and provide a screenshot of the difference between the two chains.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #204B8E; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "### Answer:\n",
    "\n",
    "Changes in metrics occur because modifications to chunk size, embedding models, or prompt design directly impact how effectively the system retrieves and answers questions. For example, a better embedding model or optimal chunk size can improve faithfulness, answer relevancy, and correctness by enabling the system to find and use more relevant information. While, suboptimal settings may lower precision or recall, affecting these metrics negatively. Comparing screenshots of evaluation results before and after such changes visually highlights these metric differences, illustrating the impact of the adjustments on system performance.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07ab3dc0790241bbb85a7f488a42ef8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7710c7377cbc4c30b55b28b4bc99e88f",
       "IPY_MODEL_41bdd49fab5f4826959d0d50663ff539",
       "IPY_MODEL_60168d85131d4afc99d55d61ab954ee6"
      ],
      "layout": "IPY_MODEL_9edf898aeeab40dda9b9475395776521"
     }
    },
    "095f680d37a3430fb82d223615662db5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b44cb0f8e34446c8dde668a75d3d8ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10df31709059484c99f102453d780473": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1160a44dc18e47b0890f70c40eaa7eb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11c7f66acc1d45be9517d0addf49331e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "122b1bd1f0e9417a8dcb57d4eebe4d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0c233ad01604540a6c873f4a731982d",
       "IPY_MODEL_e9a01115c75b499884f7e0ef32e9e599",
       "IPY_MODEL_5faba4ad609448b2b49024add4ad3b8e"
      ],
      "layout": "IPY_MODEL_ef25efa751304e4699910f1fbc14345f"
     }
    },
    "158212a630f04cbd884c937f2f60f5c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1d54ccd56494c4d831f71b416a1f880",
      "placeholder": "​",
      "style": "IPY_MODEL_530f696feefe499da08c6312047379b2",
      "value": " 20/? [01:43&lt;00:00,  5.25s/it]"
     }
    },
    "23863bc37a8645029934b8c106622c51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2508d229935744cbb5fc340222e2d660": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a0755d4476543feb4a64538e3e37213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c20b539cd70b4ba99601ad1d69fd9cec",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6d681eeafa44d18b933a4c5dec88382",
      "value": 1
     }
    },
    "33f063017b7c4c7fa8cbafc89674350b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6864c81e2bcf459bbaf5acbb36bdfcbe",
       "IPY_MODEL_59d6e269eadf429a924f6f79bc8ba4ba",
       "IPY_MODEL_ca791fc471e34b9da2f9070fc1053c0f"
      ],
      "layout": "IPY_MODEL_8baf0ed3d0f743f294e07f2b5407e820"
     }
    },
    "3a8537e37fc14fd9b16ca0ceee4fede6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41bdd49fab5f4826959d0d50663ff539": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6eb8b2e3262c45248708a2082c366f0a",
      "max": 64,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_095f680d37a3430fb82d223615662db5",
      "value": 64
     }
    },
    "530f696feefe499da08c6312047379b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59d6e269eadf429a924f6f79bc8ba4ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_890e0dd7fa524ceca1e805cb6253ee71",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_61b52ff459214129b8f7e6d67b192b78",
      "value": 20
     }
    },
    "5ab5f08afa5841709aedb2f78a52a11c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c2fda99d4204d85b1bf7ad354fd58d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5faba4ad609448b2b49024add4ad3b8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_849b5c95008541d49f1ceedf0a59ac60",
      "placeholder": "​",
      "style": "IPY_MODEL_f3665a86662746c4ac7cb0796604781d",
      "value": " 20/? [01:27&lt;00:00,  6.45s/it]"
     }
    },
    "60168d85131d4afc99d55d61ab954ee6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a8537e37fc14fd9b16ca0ceee4fede6",
      "placeholder": "​",
      "style": "IPY_MODEL_1160a44dc18e47b0890f70c40eaa7eb0",
      "value": " 61/64 [00:02&lt;00:00, 23.36it/s]"
     }
    },
    "61b52ff459214129b8f7e6d67b192b78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6864c81e2bcf459bbaf5acbb36bdfcbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10df31709059484c99f102453d780473",
      "placeholder": "​",
      "style": "IPY_MODEL_2508d229935744cbb5fc340222e2d660",
      "value": "Generating: 100%"
     }
    },
    "6eb8b2e3262c45248708a2082c366f0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7710c7377cbc4c30b55b28b4bc99e88f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c2fda99d4204d85b1bf7ad354fd58d4",
      "placeholder": "​",
      "style": "IPY_MODEL_93cd4d35c5fd41f5904ca1d52d1f52a8",
      "value": "embedding nodes:  95%"
     }
    },
    "7cb241365f604419af454c1c28de197a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "7dce19ac55264f2b88a0e4730e55867b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddffd834e09940a4bd3874c3f39b4e21",
      "placeholder": "​",
      "style": "IPY_MODEL_ef63c3b2d51e452da03cdae5d9b034be",
      "value": ""
     }
    },
    "849b5c95008541d49f1ceedf0a59ac60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "890e0dd7fa524ceca1e805cb6253ee71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8baf0ed3d0f743f294e07f2b5407e820": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93cd4d35c5fd41f5904ca1d52d1f52a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9cf586576ff44dba86ba2eb389593c61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9edf898aeeab40dda9b9475395776521": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a6d681eeafa44d18b933a4c5dec88382": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf8dcc0895054529af356da401c513f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7dce19ac55264f2b88a0e4730e55867b",
       "IPY_MODEL_2a0755d4476543feb4a64538e3e37213",
       "IPY_MODEL_158212a630f04cbd884c937f2f60f5c8"
      ],
      "layout": "IPY_MODEL_11c7f66acc1d45be9517d0addf49331e"
     }
    },
    "c20b539cd70b4ba99601ad1d69fd9cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "ca791fc471e34b9da2f9070fc1053c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23863bc37a8645029934b8c106622c51",
      "placeholder": "​",
      "style": "IPY_MODEL_5ab5f08afa5841709aedb2f78a52a11c",
      "value": " 20/20 [00:52&lt;00:00,  4.50s/it]"
     }
    },
    "d1d54ccd56494c4d831f71b416a1f880": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddffd834e09940a4bd3874c3f39b4e21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0c233ad01604540a6c873f4a731982d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b44cb0f8e34446c8dde668a75d3d8ad",
      "placeholder": "​",
      "style": "IPY_MODEL_edaac6587b2d4bd5be52b89bb097f99f",
      "value": ""
     }
    },
    "e9a01115c75b499884f7e0ef32e9e599": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cb241365f604419af454c1c28de197a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9cf586576ff44dba86ba2eb389593c61",
      "value": 1
     }
    },
    "edaac6587b2d4bd5be52b89bb097f99f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef25efa751304e4699910f1fbc14345f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef63c3b2d51e452da03cdae5d9b034be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3665a86662746c4ac7cb0796604781d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "state": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
